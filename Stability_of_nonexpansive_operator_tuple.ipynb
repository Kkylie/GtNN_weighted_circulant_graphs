{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xf_6cAJCKfl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sympy as sp\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from torcheval.metrics.functional import r2_score\n",
        "import architectures as archit\n",
        "import data as da\n",
        "import stable as sta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### graph and data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E4WrxXMDsL2",
        "outputId": "8ce68e05-deb8-4db1-9166-a230f99ab214"
      },
      "outputs": [],
      "source": [
        "num_vertices = 293 # number of vertices for two circulant graphs\n",
        "not_moving_probabilities_vector = [0.05,0.05] # weight p for the diagonal element of graph 1 and 2\n",
        "jump_sizes_vector = [1,30] # location of jump l\n",
        "n_samples = 1000 # number of data pair\n",
        "\n",
        "# generate the circulant graph tuple\n",
        "ts = da.cycle_operator_tuple(num_vertices=num_vertices,\n",
        "                    not_moving_probabilities_vector=not_moving_probabilities_vector,\n",
        "                    jump_sizes_vector=jump_sizes_vector)\n",
        "operator_tuple = ts\n",
        "\n",
        "# normalized the graph tuple\n",
        "ts_normalized = []\n",
        "for ind_g, g in enumerate(ts):\n",
        "  ts_normalized.append(g)\n",
        "  if torch.linalg.matrix_norm(g,ord = 2) > 1:\n",
        "    g_normalized = g / torch.linalg.matrix_norm(g,ord = 2)\n",
        "    print(\"Graph {:d} has norm {:.4f} bigger than 1. This graph is normalized\".format(ind_g,np.array(torch.linalg.matrix_norm(g,ord = 2))))\n",
        "    ts_normalized[ind_g] = g_normalized\n",
        "operator_tuple = (ts_normalized[0],ts_normalized[1])\n",
        "\n",
        "# generate data using the circulant graph tuple\n",
        "# y = 0.76*t1@t0@x + 0.33*t0@t1@x + 0.3*t0@t0@t0@x + noise\n",
        "x, y = da.dataLab_cycles(num_vertices=num_vertices,\n",
        "                      not_moving_probabilities_vector=not_moving_probabilities_vector,\n",
        "                      jump_sizes_vector=jump_sizes_vector,\n",
        "                      noise_stdev = 0.1,\n",
        "                      n_samples = n_samples)\n",
        "\n",
        "print(x.shape) # (number of data) * (number of features) * (number of veritces)\n",
        "print(y.shape) # (number of data) * (number of features) * (number of veritces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdFG3qfuc4sJ",
        "outputId": "93e289d2-1840-4236-a293-57619c71dcce"
      },
      "outputs": [],
      "source": [
        "# train test split\n",
        "test_data_ratio = 0.2\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_data_ratio)\n",
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# use GPU if available\n",
        "USE_GPU = True\n",
        "\n",
        "if USE_GPU:\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "X_train = X_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_train = y_train.to(device)\n",
        "y_test = y_test.to(device)\n",
        "operator_tuple_device = (operator_tuple[0].to(device),operator_tuple[1].to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjEoUI8Cc78L"
      },
      "outputs": [],
      "source": [
        "# perturbed graph tuple for stability metrics during training process\n",
        "Z_tuple, Wj_minus_Zj_norm = sta.create_perturbation_Z(operator_tuple)\n",
        "print(Wj_minus_Zj_norm)\n",
        "Z_tuple_device = (Z_tuple[0].to(device),Z_tuple[1].to(device)) # perturbed graph tuple \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_network(model, operator_tuple_device, Z_tuple_device, Wj_minus_Zj_norm, X_train, y_train, X_test, y_test, num_layer = 1, \n",
        "                  Penalty_lam = 0, Stable_Penalty = False, constrain_C_Flag = True, constrain_Cj_Flag = True, target_Upr_Cj_vec = 1, target_Upr_C = 1,\n",
        "                  n_epochs = 5000, lr = 0.01, verbose = True, Plot_loss = True):\n",
        "\n",
        "  num_vertices = X_train.shape[2]\n",
        "  loss_fcn = nn.MSELoss()\n",
        "  \n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "\n",
        "  epoch_tr_loss = []\n",
        "  epoch_ts_loss = []\n",
        "  h_poly_matrix_norm_all_GNN = []\n",
        "  hw_minus_hz_poly_matrix_norm_all_GNN=[]\n",
        "  hw_minus_hz_upper_all_GNN = []\n",
        "  C_all_GNN = []\n",
        "  C_j1_all_GNN = []\n",
        "  C_j2_all_GNN = []\n",
        "  for epoch in range(n_epochs):\n",
        "    # training\n",
        "    model.train()\n",
        "    outs_train = model.forward(X_train)\n",
        "    loss = loss_fcn(outs_train, y_train)\n",
        "\n",
        "    # stability penalty\n",
        "    if Stable_Penalty:\n",
        "      loss = loss + Penalty_lam * sta.compute_penalty(model, target_Upr_Cj_vec, Upr_C = target_Upr_C,\n",
        "                                                constrain_C_Flag = constrain_C_Flag, constrain_Cj_Flag = constrain_Cj_Flag)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_tr_loss.append(loss.item())\n",
        "    y_train_reshape = torch.reshape(y_train,(y_train.shape[0],y_train.shape[1]*y_train.shape[2]))\n",
        "    outs_train_reshape = torch.reshape(outs_train,(outs_train.shape[0],outs_train.shape[1]*outs_train.shape[2]))\n",
        "    #R2Score\n",
        "    R2_train = r2_score(outs_train_reshape, y_train_reshape)\n",
        "\n",
        "\n",
        "    # testing\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      outs_test = model.forward(X_test)\n",
        "      y_test_reshape = torch.reshape(y_test,(y_test.shape[0],y_test.shape[1]*y_test.shape[2]))\n",
        "      outs_test_reshape = torch.reshape(outs_test,(outs_test.shape[0],outs_test.shape[1]*outs_test.shape[2]))\n",
        "      R2_test = r2_score(outs_test_reshape, y_test_reshape)\n",
        "      GNN_test_loss = loss_fcn(outs_test, y_test)\n",
        "      Penalty_test_loss = 0\n",
        "      # stability penalty\n",
        "      if Stable_Penalty:\n",
        "        Penalty_test_loss = sta.compute_penalty(model, target_Upr_Cj_vec, Upr_C = target_Upr_C,\n",
        "                                            constrain_C_Flag = constrain_C_Flag, constrain_Cj_Flag = constrain_Cj_Flag)\n",
        "      Test_loss = GNN_test_loss + Penalty_lam * Penalty_test_loss\n",
        "      epoch_ts_loss.append(Test_loss)\n",
        "\n",
        "    # compute stability metrics for 1-layer model\n",
        "    if num_layer == 1:\n",
        "      h_poly_matrix_norm_all_GNN.append(sta.compute_h_poly_matrix_norm(model, num_vertices))\n",
        "      hw_minus_hz_poly_matrix_norm_all_GNN.append(sta.compute_hw_minus_hz_poly_matrix_norm(model, num_vertices, operator_tuple_device, Z_tuple_device))\n",
        "\n",
        "      C_max_sum_train_GNN, C_j_max_sum_train_GNN = sta.compute_constrain_param(model)\n",
        "      C_max_sum_train_GNN = C_max_sum_train_GNN[0]\n",
        "      C_j_max_sum_train_GNN = C_j_max_sum_train_GNN[0]\n",
        "      C_all_GNN.append(C_max_sum_train_GNN.data)\n",
        "      C_j1_all_GNN.append(C_j_max_sum_train_GNN[0].data)\n",
        "      C_j2_all_GNN.append(C_j_max_sum_train_GNN[1].data)\n",
        "      hw_minus_hz_upper_bound = C_j_max_sum_train_GNN.data.cpu() @ Wj_minus_Zj_norm\n",
        "      hw_minus_hz_upper_all_GNN.append(hw_minus_hz_upper_bound)\n",
        "\n",
        "\n",
        "    if verbose and (epoch % 10 == 0):\n",
        "      print(\"Epoch {:05d} | Train Loss {:.4f} | Train_R^2 {:.4f} | Test Loss {:.4f} | Test_R^2 {:.4f} | Test GNN loss {:.4f} | Test penalty loss {:.4f} |\".\n",
        "            format(epoch,  epoch_tr_loss[epoch], R2_train, epoch_ts_loss[epoch], R2_test, GNN_test_loss, Penalty_test_loss))\n",
        "\n",
        "\n",
        "  epoch_ts_loss = torch.stack(epoch_ts_loss).cpu()\n",
        "\n",
        "  if Plot_loss:\n",
        "    fig = plt.figure()\n",
        "    epoch_seq=np.arange(100, len(epoch_tr_loss) + 1)\n",
        "    plt.plot(epoch_seq, epoch_tr_loss[99:],'.-')\n",
        "    plt.plot(epoch_seq, epoch_ts_loss[99:],'r.-')\n",
        "    plt.grid()\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Curve')\n",
        "    plt.legend(['Training', 'Test'])\n",
        "    plt.show()\n",
        "\n",
        "  return R2_test, h_poly_matrix_norm_all_GNN, hw_minus_hz_poly_matrix_norm_all_GNN, hw_minus_hz_upper_all_GNN, C_all_GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### create monomial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_variable = 2\n",
        "allowed_degree = 3\n",
        "M = archit.MonomialWordSupport(num_variables=num_variable, allowed_degree = allowed_degree, device = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0Ta_HgAsZJM"
      },
      "source": [
        "### 1-layer GtNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_epochs=6000\n",
        "num_features_in = 1\n",
        "num_features_out = 1\n",
        "Stable_Penalty = False\n",
        "h_poly_matrix_norm_all_GNN = []\n",
        "hw_minus_hz_poly_matrix_norm_all_GNN=[]\n",
        "hw_minus_hz_upper_all_GNN = []\n",
        "C_all_GNN = []\n",
        "\n",
        "# evaluate monomial for training graph tuple\n",
        "M.evaluate_at_operator_tuple(operator_tuple=operator_tuple_device)\n",
        "\n",
        "# 1-layer GtNN model\n",
        "model_GNN = archit.OperatorFilterLayer(num_features_in = num_features_in,\n",
        "                                            num_features_out = num_features_out, monomial_word_support = M)\n",
        "model_GNN.to(device)\n",
        "\n",
        "# training\n",
        "result_GNN, h_poly_matrix_norm_all_GNN, hw_minus_hz_poly_matrix_norm_all_GNN, hw_minus_hz_upper_all_GNN, C_all_GNN = train_network(\n",
        "    model_GNN, operator_tuple_device, Z_tuple_device, Wj_minus_Zj_norm, X_train, y_train, X_test, y_test, \n",
        "    Stable_Penalty = Stable_Penalty, n_epochs = n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# final testing R^2\n",
        "print(result_GNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "vrDAgsMznaZW",
        "outputId": "9a0244ae-a979-4595-9596-19cdeba809d5"
      },
      "outputs": [],
      "source": [
        "# plot 1-layer GtNN stability metrics\n",
        "h_poly_matrix_norm_all_GNN = torch.stack(h_poly_matrix_norm_all_GNN).cpu()\n",
        "C_all_GNN = torch.stack(C_all_GNN).cpu()\n",
        "hw_minus_hz_poly_matrix_norm_all_GNN = torch.stack(hw_minus_hz_poly_matrix_norm_all_GNN).cpu()\n",
        "hw_minus_hz_upper_all_GNN = torch.stack(hw_minus_hz_upper_all_GNN).cpu()\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "epoch_seq2 = np.arange(0, len(h_poly_matrix_norm_all_GNN) )\n",
        "plt.rc('font',size=15)\n",
        "plt.plot(epoch_seq2,h_poly_matrix_norm_all_GNN,'-',label='operator norm of h(T)')\n",
        "plt.plot(epoch_seq2,C_all_GNN,'-', label = 'C(h)')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('stability metric')\n",
        "plt.title('GtNN')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.rc('font',size=15)\n",
        "plt.plot(epoch_seq2,hw_minus_hz_poly_matrix_norm_all_GNN,'-',label='operator norm of h(W) - h(T)')\n",
        "plt.plot(epoch_seq2,hw_minus_hz_upper_all_GNN,'-', label = 'upper bound on operator norm of h(W) - h(T)' )\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('stability metric')\n",
        "plt.title('GtNN')\n",
        "plt.legend(fontsize=12)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save data\n",
        "torch.save(h_poly_matrix_norm_all_GNN, 'h_poly_matrix_norm_all_GNN.pt')\n",
        "torch.save(C_all_GNN, 'C_all_GNN.pt')\n",
        "torch.save(hw_minus_hz_poly_matrix_norm_all_GNN, 'hw_minus_hz_poly_matrix_norm_all_GNN.pt')\n",
        "torch.save(hw_minus_hz_upper_all_GNN, 'hw_minus_hz_upper_all_GNN.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HQUpEDTsmuy"
      },
      "source": [
        "### 1-layer stable GtNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMZtvs6oC0Ai",
        "outputId": "3846c495-381a-4fd4-9254-c1743a8b3413"
      },
      "outputs": [],
      "source": [
        "# Compute expansion constant for 1-layer GtNN\n",
        "C_max_sum, C_j_max_sum = sta.compute_constrain_param(model_GNN)\n",
        "print(C_max_sum)\n",
        "print(C_j_max_sum)\n",
        "\n",
        "# Set the target expansion constant for stable GtNN as 1/2 of the GtNN\n",
        "target_Upr_C = []\n",
        "target_Upr_Cj_vec = []\n",
        "for C_max_sum_each_layer in C_max_sum:\n",
        "  target_Upr_C.append(C_max_sum_each_layer.data/2)\n",
        "\n",
        "for C_j_max_sum_each_layer in C_j_max_sum:\n",
        "  target_Upr_Cj_vec.append(C_j_max_sum_each_layer.data/2)\n",
        "\n",
        "print(target_Upr_C)\n",
        "print(target_Upr_Cj_vec)\n",
        "\n",
        "C_max_sum = C_max_sum[0]\n",
        "C_j_max_sum = C_j_max_sum[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_epochs=6000\n",
        "Penalty_lam = 10 # penatly coefficient\n",
        "Stable_Penalty = True\n",
        "h_poly_matrix_norm_all_stable = []\n",
        "hw_minus_hz_poly_matrix_norm_all_stable=[]\n",
        "hw_minus_hz_upper_all_stable = []\n",
        "C_all_stable = []\n",
        "\n",
        "# evaluate monomial for training graph tuple\n",
        "M.evaluate_at_operator_tuple(operator_tuple=operator_tuple_device)\n",
        "\n",
        "# 1-layer stable GtNN model\n",
        "model_stable = archit.OperatorFilterLayer(num_features_in = num_features_in,\n",
        "                                            num_features_out = num_features_out, monomial_word_support = M)\n",
        "model_stable.to(device)\n",
        "\n",
        "# training\n",
        "result_stable, h_poly_matrix_norm_all_stable, hw_minus_hz_poly_matrix_norm_all_stable, hw_minus_hz_upper_all_stable, C_all_stable = train_network(\n",
        "    model_stable, operator_tuple_device, Z_tuple_device, Wj_minus_Zj_norm, X_train, y_train, X_test, y_test, \n",
        "    Penalty_lam = Penalty_lam, Stable_Penalty = Stable_Penalty, target_Upr_Cj_vec = target_Upr_Cj_vec, target_Upr_C = target_Upr_C,\n",
        "    n_epochs = n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# final testing R^2\n",
        "print(result_stable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "XA5AGmSHo1Vc",
        "outputId": "2b6c44d6-4d26-4f83-eb0b-e69bb3aff969"
      },
      "outputs": [],
      "source": [
        "# plot 1-layer stable GtNN stability metrics\n",
        "h_poly_matrix_norm_all_stable = torch.stack(h_poly_matrix_norm_all_stable).cpu()\n",
        "C_all_stable = torch.stack(C_all_stable).cpu()\n",
        "hw_minus_hz_poly_matrix_norm_all_stable = torch.stack(hw_minus_hz_poly_matrix_norm_all_stable).cpu()\n",
        "hw_minus_hz_upper_all_stable = torch.stack(hw_minus_hz_upper_all_stable).cpu()\n",
        "\n",
        "fig = plt.figure()\n",
        "epoch_seq_stable2 = np.arange(0, len(h_poly_matrix_norm_all_stable) )\n",
        "plt.rc('font',size=15)\n",
        "plt.plot(epoch_seq_stable2,h_poly_matrix_norm_all_stable,'-',label='operator norm of h(T)', alpha =0.7)\n",
        "plt.plot(epoch_seq_stable2,C_all_stable,'-', label = 'C(h)', alpha =0.7)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('stability metric')\n",
        "plt.title('stable GtNN')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(epoch_seq_stable2,hw_minus_hz_poly_matrix_norm_all_stable,'-',label='operator norm of h(W) - h(T)', alpha =0.7)\n",
        "plt.plot(epoch_seq_stable2,hw_minus_hz_upper_all_stable,'-', label = 'upper bound on operator norm of h(W) - h(T)', alpha =0.7)\n",
        "plt.rc('font',size=15)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('stability metric')\n",
        "plt.title('stable GtNN')\n",
        "plt.legend(fontsize = 12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(h_poly_matrix_norm_all_stable, 'h_poly_matrix_norm_all_stable.pt')\n",
        "torch.save(C_all_stable, 'C_all_stable.pt')\n",
        "torch.save(hw_minus_hz_poly_matrix_norm_all_stable, 'hw_minus_hz_poly_matrix_norm_all_stable.pt')\n",
        "torch.save(hw_minus_hz_upper_all_stable, 'hw_minus_hz_upper_all_stable.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv9DmybZbhhK",
        "outputId": "a6bbbf45-0a83-4982-dd11-d69f5f342fd0"
      },
      "outputs": [],
      "source": [
        "# print expanion constant to check if satisfy constraints\n",
        "C_max_sum_stable, C_j_max_sum_stable = sta.compute_constrain_param(model_stable)\n",
        "C_max_sum_stable = C_max_sum_stable[0]\n",
        "C_j_max_sum_stable = C_j_max_sum_stable[0]\n",
        "print(C_max_sum_stable)\n",
        "print(C_j_max_sum_stable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### plot figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# combine graph for stability metric for GtNN and stabe GtNN (if same number of epochs)\n",
        "fig = plt.figure()\n",
        "epoch_seq_stable2 = np.arange(0, len(h_poly_matrix_norm_all_stable) )\n",
        "plt.rc('font',size=20)\n",
        "plt.plot(epoch_seq_stable2,C_all_GNN,'--', color= 'tab:orange', label = 'GtNN: $C(h)$', alpha =0.7)\n",
        "plt.plot(epoch_seq_stable2,h_poly_matrix_norm_all_GNN,'-',color= 'tab:orange', label='GtNN: $\\|h(T)\\|_{op}$', alpha =0.7)\n",
        "plt.plot(epoch_seq_stable2,C_all_stable,'--',  color= 'tab:blue', label = 'stable GtNN: $C(h)$', alpha =0.7)\n",
        "plt.plot(epoch_seq_stable2,h_poly_matrix_norm_all_stable,'-', color= 'tab:blue',label='stable GtNN: $\\|h(T)\\|_{op}$', alpha =0.7)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('stability metric')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.rc('font',size=20)\n",
        "plt.plot(epoch_seq_stable2,hw_minus_hz_upper_all_GNN,'--', color= 'tab:orange', label = 'GtNN: $\\|h(W) - h(T)\\|_{op}$ bound', alpha =0.7)\n",
        "plt.plot(epoch_seq_stable2,hw_minus_hz_poly_matrix_norm_all_GNN,'-', color= 'tab:orange',label='GtNN: $\\|h(W) - h(T)\\|_{op}$', alpha =0.7)\n",
        "plt.plot(epoch_seq_stable2,hw_minus_hz_upper_all_stable,'--',color= 'tab:blue', label = 'stable GtNN: $\\|h(W) - h(T)\\|_{op}$ bound', alpha =0.7)\n",
        "plt.plot(epoch_seq_stable2,hw_minus_hz_poly_matrix_norm_all_stable,'-',color= 'tab:blue',label='stable GtNN: $\\|h(W) - h(T)\\|_{op}$', alpha =0.7)\n",
        "plt.xlabel('epochs',fontsize = 20)\n",
        "plt.ylabel('stability metric', fontsize = 20)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAH8pxHS0ms-"
      },
      "source": [
        "### 2-layer GtNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_epochs=8000\n",
        "num_features_in = 1\n",
        "num_features_out = 1\n",
        "num_features_hidden = 2\n",
        "num_layer = 2\n",
        "Stable_Penalty = False\n",
        "h_poly_matrix_norm_all_twolayer = []\n",
        "hw_minus_hz_poly_matrix_norm_all_twolayer=[]\n",
        "hw_minus_hz_upper_all_twolayer = []\n",
        "C_all_twolayer = []\n",
        "\n",
        "# evaluate monomial for training graph tuple\n",
        "M.evaluate_at_operator_tuple(operator_tuple=operator_tuple_device)\n",
        "\n",
        "# 2-layer GtNN model\n",
        "model_two_layer_GNN = archit.TwoLayerWithReLU(num_features_in = num_features_in, num_features_out = num_features_out, \n",
        "                                              num_features_hidden = num_features_hidden, monomial_word_support = M)\n",
        "model_two_layer_GNN.to(device)\n",
        "\n",
        "# training\n",
        "result_twolayer, h_poly_matrix_norm_all_twolayer, hw_minus_hz_poly_matrix_norm_all_twolayer, hw_minus_hz_upper_all_twolayer, C_all_twolayer = train_network(\n",
        "    model_two_layer_GNN, operator_tuple_device, Z_tuple_device, Wj_minus_Zj_norm, X_train, y_train, X_test, y_test, num_layer = num_layer,\n",
        "    Stable_Penalty = Stable_Penalty, n_epochs = n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# final testing R^2\n",
        "print(result_twolayer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGyzd7ZIuc-e"
      },
      "source": [
        "### 2-layer GtNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LypgCKoQug6a",
        "outputId": "8f9afaf5-1705-42b2-94e5-d0ff8419864c"
      },
      "outputs": [],
      "source": [
        "# Compute expansion constant for 2-layer GtNN\n",
        "[C_max_sum_all_layer, C_j_max_sum_all_layer] = sta.compute_constrain_param(model_two_layer_GNN)\n",
        "print(C_max_sum_all_layer)\n",
        "print(C_j_max_sum_all_layer)\n",
        "\n",
        "# Set the target expansion constant for 2-layer stable GtNN as 1/2 of the 2-layer GtNN\n",
        "target_Upr_C_all_layer = []\n",
        "target_Upr_Cj_all_layer = []\n",
        "for C_max_sum_each_layer in C_max_sum_all_layer:\n",
        "  target_Upr_C_all_layer.append(C_max_sum_each_layer.data/2)\n",
        "\n",
        "for C_j_max_sum_each_layer in C_j_max_sum_all_layer:\n",
        "  target_Upr_Cj_all_layer.append(C_j_max_sum_each_layer.data/2)\n",
        "\n",
        "print(target_Upr_C_all_layer)\n",
        "print(target_Upr_Cj_all_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_epochs=8000\n",
        "Penalty_lam = 10 # penatly coefficient\n",
        "Stable_Penalty = True\n",
        "h_poly_matrix_norm_all_twolayer_stable = []\n",
        "hw_minus_hz_poly_matrix_norm_all_twolayer_stable=[]\n",
        "hw_minus_hz_upper_all_twolayer_stable = []\n",
        "C_all_twolayer_stable = []\n",
        "\n",
        "# evaluate monomial for training graph tuple\n",
        "M.evaluate_at_operator_tuple(operator_tuple=operator_tuple_device)\n",
        "\n",
        "# 2-layer stable GtNN model\n",
        "model_two_layer_stable = archit.TwoLayerWithReLU(num_features_in = num_features_in, num_features_out = num_features_out, \n",
        "                                              num_features_hidden = num_features_hidden, monomial_word_support = M)\n",
        "model_two_layer_stable.to(device)\n",
        "\n",
        "# training\n",
        "result_twolayer_stable, h_poly_matrix_norm_all_twolayer_stable, hw_minus_hz_poly_matrix_norm_all_twolayer_stable, hw_minus_hz_upper_all_twolayer_stable, C_all_twolayer_stable = train_network(\n",
        "    model_two_layer_stable, operator_tuple_device, Z_tuple_device, Wj_minus_Zj_norm, X_train, y_train, X_test, y_test, num_layer = num_layer,\n",
        "    Penalty_lam = Penalty_lam, Stable_Penalty = Stable_Penalty, target_Upr_Cj_vec = target_Upr_Cj_all_layer, target_Upr_C = target_Upr_C_all_layer,\n",
        "    n_epochs = n_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# final testing R^2\n",
        "print(result_twolayer_stable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khL1GRNT8Tt-"
      },
      "outputs": [],
      "source": [
        "# print expanion constant to check if satisfy constraints\n",
        "[C_max_sum_two_layer_stable, C_j_max_sum_two_layer_stable] = sta.compute_constrain_param(model_two_layer_stable)\n",
        "print(C_max_sum_two_layer_stable)\n",
        "print(C_j_max_sum_two_layer_stable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoJajtbcsxPo"
      },
      "source": [
        "### output perturbation for different graph perturbation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCKKi540mqoI"
      },
      "outputs": [],
      "source": [
        "Perturbation_norm_all = np.arange(0,5,0.5) # initial peturbation size\n",
        "num_perturb_norm = len(Perturbation_norm_all) # number of different size of peturbation\n",
        "num_perturb = 10 # number of repeated peturbation for each size\n",
        "\n",
        "out_perturb_GNN_all = np.zeros((num_perturb,num_perturb_norm)) # output perturbation for 1-layer GtNN\n",
        "out_perturb_stable_all = np.zeros((num_perturb,num_perturb_norm)) # output perturbation for 1-layer stable GtNN\n",
        "out_perturb_two_layer_GNN_all = np.zeros((num_perturb,num_perturb_norm)) # output perturbation for 2-layer GtNN\n",
        "out_perturb_two_layer_stable_all = np.zeros((num_perturb,num_perturb_norm)) # output perturbation for 2-layer stable GtNN\n",
        "\n",
        "diff_out_perturb = np.zeros((num_perturb,num_perturb_norm))\n",
        "relative_diff_out = np.zeros((num_perturb,num_perturb_norm))\n",
        "\n",
        "# R^2 on testing graph\n",
        "R2_test_GNN = np.zeros((num_perturb,num_perturb_norm))\n",
        "R2_test_hat_GNN = np.zeros((num_perturb,num_perturb_norm))\n",
        "R2_test_stable = np.zeros((num_perturb,num_perturb_norm))\n",
        "R2_test_hat_stable = np.zeros((num_perturb,num_perturb_norm))\n",
        "R2_test_two_layer_GNN = np.zeros((num_perturb,num_perturb_norm))\n",
        "R2_test_hat_two_layer_GNN = np.zeros((num_perturb,num_perturb_norm))\n",
        "R2_test_two_layer_stable = np.zeros((num_perturb,num_perturb_norm))\n",
        "R2_test_hat_two_layer_stable = np.zeros((num_perturb,num_perturb_norm))\n",
        "\n",
        "# actual peturbation size after normalizaion\n",
        "actual_peturbation_size = np.zeros((num_perturb,num_perturb_norm,2))\n",
        "\n",
        "for ind_perturb, trainStabilityEpsilon in enumerate(Perturbation_norm_all):\n",
        "  for i in range(num_perturb):\n",
        "\n",
        "    # create perturbed graph tuple\n",
        "    ts_perturb = []\n",
        "    for ind_g, g in enumerate(operator_tuple):\n",
        "      actual_peturbation_size[i,ind_perturb,ind_g] = trainStabilityEpsilon\n",
        "      if trainStabilityEpsilon > 0:\n",
        "        S = g\n",
        "        E = torch.rand(size=S.shape)\n",
        "        E = torch.triu(E) + torch.triu(E,diagonal = 1).t()\n",
        "        E = trainStabilityEpsilon * E / torch.linalg.matrix_norm(E,ord = 2)\n",
        "        S_hat= S + E # additive perturbation\n",
        "      else:\n",
        "        S_hat = g\n",
        "\n",
        "      # normalized perturbed graph \n",
        "      if torch.linalg.matrix_norm(S_hat,ord = 2) > 1:\n",
        "        S_hat = S_hat / torch.linalg.matrix_norm(S_hat,ord = 2)\n",
        "        E_actual = S_hat - S\n",
        "        # compute actual peturbation size after normalizaion\n",
        "        trainStabilityEpsilon_actual = torch.linalg.matrix_norm(E_actual,ord = 2)\n",
        "        actual_peturbation_size[i,ind_perturb,ind_g] = trainStabilityEpsilon_actual\n",
        "      ts_perturb.append(S_hat)\n",
        "    ts_perturb_tuple = (ts_perturb[0],ts_perturb[1])\n",
        "    ts_perturb_tuple_device = (ts_perturb[0].to(device),ts_perturb[1].to(device))\n",
        "\n",
        "    # evaluate stability performance for 1-layer GtNN\n",
        "    model_GNN.eval()\n",
        "    with torch.no_grad():\n",
        "      # evaluate on original graph tuple\n",
        "      M.evaluate_at_operator_tuple(operator_tuple=operator_tuple_device)\n",
        "      model_GNN.change_monomial_word_support(M)\n",
        "      outs_test = model_GNN.forward(X_test)\n",
        "\n",
        "      # compute testing R^2 for original graph tuple\n",
        "      y_test_reshape = torch.reshape(y_test,(y_test.shape[0],y_test.shape[1]*y_test.shape[2]))\n",
        "      outs_test_reshape = torch.reshape(outs_test,(outs_test.shape[0],outs_test.shape[1]*outs_test.shape[2]))\n",
        "      R2_test_GNN[i,ind_perturb] = r2_score(outs_test_reshape, y_test_reshape)\n",
        "\n",
        "      # evaluate on perturbed graph tuple\n",
        "      M.evaluate_at_operator_tuple(operator_tuple = ts_perturb_tuple_device)\n",
        "      model_GNN.change_monomial_word_support(M)\n",
        "      outs_test_hat = model_GNN.forward(X_test)\n",
        "\n",
        "      #compute testing R^2 for perturbed graph tuple\n",
        "      outs_test_hat_reshape = torch.reshape(outs_test_hat,(outs_test_hat.shape[0],outs_test_hat.shape[1]*outs_test_hat.shape[2]))\n",
        "      R2_test_hat_GNN[i,ind_perturb] = r2_score(outs_test_hat_reshape, y_test_reshape)\n",
        "\n",
        "      # compute output perturbation\n",
        "      out_perturb_GNN = torch.norm(outs_test - outs_test_hat)\n",
        "      print(\"GtNN out_perturb for %d:\"%i)\n",
        "      print(out_perturb_GNN.cpu().numpy())\n",
        "\n",
        "    # evaluate stability performance for 1-layer stable GtNN\n",
        "    model_stable.eval()\n",
        "    with torch.no_grad():\n",
        "      # evaluate on original graph tuple\n",
        "      M.evaluate_at_operator_tuple(operator_tuple=operator_tuple_device)\n",
        "      model_stable.change_monomial_word_support(M)\n",
        "      outs_test_stable = model_stable.forward(X_test)\n",
        "\n",
        "      # compute testing R^2 for original graph tuple\n",
        "      y_test_reshape = torch.reshape(y_test,(y_test.shape[0],y_test.shape[1]*y_test.shape[2]))\n",
        "      outs_test_stable_reshape = torch.reshape(outs_test_stable,(outs_test_stable.shape[0],outs_test_stable.shape[1]*outs_test_stable.shape[2]))\n",
        "      R2_test_stable[i,ind_perturb] = r2_score(outs_test_stable_reshape, y_test_reshape)\n",
        "\n",
        "      # evaluate on perturbed graph tuple\n",
        "      M.evaluate_at_operator_tuple(operator_tuple = ts_perturb_tuple_device)\n",
        "      model_stable.change_monomial_word_support(M)\n",
        "      outs_test_stable_hat = model_stable.forward(X_test)\n",
        "\n",
        "      #compute testing R^2 for perturbed graph tuple\n",
        "      outs_test_hat_stable_reshape = torch.reshape(outs_test_stable_hat,(outs_test_stable_hat.shape[0],outs_test_stable_hat.shape[1]*outs_test_stable_hat.shape[2]))\n",
        "      R2_test_hat_stable[i,ind_perturb] = r2_score(outs_test_hat_stable_reshape, y_test_reshape)\n",
        "\n",
        "      # compute output perturbation\n",
        "      out_perturb_Stable = torch.norm(outs_test_stable - outs_test_stable_hat)\n",
        "      print(\"stable GtNN out_perturb for %d:\"%i)\n",
        "      print(out_perturb_Stable.cpu().numpy())\n",
        "\n",
        "    # evaluate stability performance for 2-layer GtNN\n",
        "    model_two_layer_GNN.eval()\n",
        "    with torch.no_grad():\n",
        "      #evaluate on original graph tuple\n",
        "      M.evaluate_at_operator_tuple(operator_tuple=operator_tuple_device)\n",
        "      model_two_layer_GNN.change_monomial_word_support(M)\n",
        "      outs_test_two_layer_GNN = model_two_layer_GNN.forward(X_test)\n",
        "\n",
        "      # compute testing R^2 for original graph tuple\n",
        "      y_test_reshape = torch.reshape(y_test,(y_test.shape[0],y_test.shape[1]*y_test.shape[2]))\n",
        "      outs_test_two_layer_GNN_reshape = torch.reshape(outs_test_two_layer_GNN,(outs_test_two_layer_GNN.shape[0],outs_test_two_layer_GNN.shape[1]*outs_test_two_layer_GNN.shape[2]))\n",
        "      R2_test_two_layer_GNN[i,ind_perturb] = r2_score(outs_test_two_layer_GNN_reshape, y_test_reshape)\n",
        "\n",
        "      # evaluate on perturbed graph tuple\n",
        "      M.evaluate_at_operator_tuple(operator_tuple = ts_perturb_tuple_device)\n",
        "      model_two_layer_GNN.change_monomial_word_support(M)\n",
        "      outs_test_two_layer_GNN_hat = model_two_layer_GNN.forward(X_test)\n",
        "\n",
        "      #compute testing R^2 for perturbed graph tuple\n",
        "      outs_test_hat_two_layer_GNN_reshape = torch.reshape(outs_test_two_layer_GNN_hat,(outs_test_two_layer_GNN_hat.shape[0],outs_test_two_layer_GNN_hat.shape[1]*outs_test_two_layer_GNN_hat.shape[2]))\n",
        "      R2_test_hat_two_layer_GNN[i,ind_perturb] = r2_score(outs_test_hat_two_layer_GNN_reshape, y_test_reshape)\n",
        "\n",
        "      # compute output perturbation\n",
        "      out_perturb_two_layer_GNN = torch.norm(outs_test_two_layer_GNN - outs_test_two_layer_GNN_hat)\n",
        "      print(\"two layer GtNN out_perturb for %d:\"%i)\n",
        "      print(out_perturb_two_layer_GNN.cpu().numpy())\n",
        "\n",
        "    # evaluate stability performance for 2-layer stable GtNN\n",
        "    model_two_layer_stable.eval()\n",
        "    with torch.no_grad():\n",
        "      #evaluate on original graph tuple\n",
        "      M.evaluate_at_operator_tuple(operator_tuple=operator_tuple_device)\n",
        "      model_two_layer_stable.change_monomial_word_support(M)\n",
        "      outs_test_two_layer_stable = model_two_layer_stable.forward(X_test)\n",
        "\n",
        "      # compute testing R^2 for original graph tuple\n",
        "      y_test_reshape = torch.reshape(y_test,(y_test.shape[0],y_test.shape[1]*y_test.shape[2]))\n",
        "      outs_test_two_layer_stable_reshape = torch.reshape(outs_test_two_layer_stable,(outs_test_two_layer_stable.shape[0],outs_test_two_layer_stable.shape[1]*outs_test_two_layer_stable.shape[2]))\n",
        "      R2_test_two_layer_stable[i,ind_perturb] = r2_score(outs_test_two_layer_stable_reshape, y_test_reshape)\n",
        "\n",
        "      # evaluate on perturbed graph tuple\n",
        "      M.evaluate_at_operator_tuple(operator_tuple = ts_perturb_tuple_device)\n",
        "      model_two_layer_stable.change_monomial_word_support(M)\n",
        "      outs_test_two_layer_stable_hat = model_two_layer_stable.forward(X_test)\n",
        "\n",
        "      #compute testing R^2 for perturbed graph tuple\n",
        "      outs_test_hat_two_layer_stable_reshape = torch.reshape(outs_test_two_layer_stable_hat,(outs_test_two_layer_stable_hat.shape[0],outs_test_two_layer_stable_hat.shape[1]*outs_test_two_layer_stable_hat.shape[2]))\n",
        "      R2_test_hat_two_layer_stable[i,ind_perturb] = r2_score(outs_test_hat_two_layer_stable_reshape, y_test_reshape)\n",
        "\n",
        "      # compute output perturbation\n",
        "      out_perturb_two_layer_stable = torch.norm(outs_test_two_layer_stable - outs_test_two_layer_stable_hat)\n",
        "      print(\"two layer stable GtNN out_perturb for %d:\"%i)\n",
        "      print(out_perturb_two_layer_stable.cpu().numpy())\n",
        "\n",
        "    out_perturb_GNN_all[i,ind_perturb] = out_perturb_GNN.cpu().numpy()\n",
        "    out_perturb_stable_all[i,ind_perturb] = out_perturb_Stable.cpu().numpy()\n",
        "    out_perturb_two_layer_GNN_all[i,ind_perturb] = out_perturb_two_layer_GNN.cpu().numpy()\n",
        "    out_perturb_two_layer_stable_all[i,ind_perturb] = out_perturb_two_layer_stable.cpu().numpy()\n",
        "    diff_out_perturb[i,ind_perturb] = out_perturb_GNN.cpu().numpy() - out_perturb_Stable.cpu().numpy()\n",
        "    relative_diff_out[i,ind_perturb] = diff_out_perturb[i,ind_perturb] / out_perturb_Stable.cpu().numpy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MirNn7haWW0"
      },
      "outputs": [],
      "source": [
        "# R^2 on perturbed graph tuple\n",
        "actual_peturbation_size_avg_j = np.mean(actual_peturbation_size,axis = 2)\n",
        "plt.scatter(actual_peturbation_size_avg_j, R2_test_hat_GNN,marker='.',label='GtNN')\n",
        "plt.scatter(actual_peturbation_size_avg_j,R2_test_hat_stable,marker='.',label='stable GtNN')\n",
        "plt.scatter(actual_peturbation_size_avg_j, R2_test_hat_two_layer_GNN,marker='.',label='two layer GtNN')\n",
        "plt.scatter(actual_peturbation_size_avg_j,R2_test_hat_two_layer_stable,marker='.',label='two layer stable GtNN')\n",
        "plt.legend()\n",
        "plt.xlabel(\"size of graph perturbation\")\n",
        "plt.ylabel(\"R square on perturbed graph\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HRDNd2Bobjr"
      },
      "outputs": [],
      "source": [
        "# output perturbation figure\n",
        "actual_peturbation_size_avg_j = np.mean(actual_peturbation_size,axis = 2)\n",
        "plt.rc('font',size=20)\n",
        "plt.scatter(actual_peturbation_size_avg_j, out_perturb_GNN_all,label='GtNN',marker='.', alpha = 1)\n",
        "plt.scatter(actual_peturbation_size_avg_j,out_perturb_stable_all,label='stable GtNN',marker='.', alpha = 1)\n",
        "plt.scatter(actual_peturbation_size_avg_j, out_perturb_two_layer_GNN_all,label='two layer GtNN', marker='.', alpha = 1)\n",
        "plt.scatter(actual_peturbation_size_avg_j,out_perturb_two_layer_stable_all,label='two layer stable GtNN',marker='.', alpha = 1)\n",
        "plt.legend(fontsize=15)\n",
        "plt.xlabel(\"size of graph perturbation\")\n",
        "plt.ylabel(\"output perturbation\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save data\n",
        "with open('peturbation.npy', 'wb') as f:\n",
        "    np.save(f,actual_peturbation_size_avg_j)\n",
        "    np.save(f,out_perturb_GNN_all)\n",
        "    np.save(f,out_perturb_stable_all)\n",
        "    np.save(f,out_perturb_two_layer_GNN_all)\n",
        "    np.save(f,out_perturb_two_layer_stable_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoW_i7VM2h9b"
      },
      "source": [
        "### output perturbation for different input node features perturbation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkPkAioq2Gxe"
      },
      "outputs": [],
      "source": [
        "Perturbation_feature_all = np.arange(0,10,0.1) # peturbation size\n",
        "num_perturb_feature = len(Perturbation_feature_all) # number of perturbation size\n",
        "\n",
        "out_perturb_feature_GNN_all = np.zeros((X_test.shape[0], num_perturb_feature)) # output perturbation for 1-layer GtNN\n",
        "out_perturb_feature_stable_all = np.zeros((X_test.shape[0], num_perturb_feature)) # output perturbation for 1-layer stable GtNN\n",
        "out_perturb_feature_two_layer_GNN_all = np.zeros((X_test.shape[0], num_perturb_feature)) # output perturbation for 2-layer GtNN\n",
        "out_perturb_feature_two_layer_stable_all = np.zeros((X_test.shape[0], num_perturb_feature)) # output perturbation for 2-layer stable GtNN\n",
        "\n",
        "for ind_perturb, trainStabilityEpsilon in enumerate(Perturbation_feature_all):\n",
        "  # create perturbed input\n",
        "  E_feature = torch.rand(size=X_test.shape)\n",
        "  E_feature = E_feature.to(device)\n",
        "  E_feature_norm_each_data = torch.max(torch.linalg.vector_norm(E_feature,ord = 2,dim = 2),dim=1)[0]\n",
        "  E_feature_fix_size = trainStabilityEpsilon * E_feature / E_feature_norm_each_data[:, None, None]\n",
        "  X_test_hat = X_test + E_feature_fix_size\n",
        "\n",
        "  # evaluate stability performance for 1-layer GtNN\n",
        "  model_GNN.eval()\n",
        "  with torch.no_grad():\n",
        "    M.evaluate_at_operator_tuple(operator_tuple=operator_tuple_device)\n",
        "    model_GNN.change_monomial_word_support(M)\n",
        "    outs_test = model_GNN.forward(X_test)\n",
        "    outs_test_hat = model_GNN.forward(X_test_hat)\n",
        "    # output perturbation\n",
        "    out_perturb_feature_GNN = torch.max(torch.linalg.vector_norm(outs_test - outs_test_hat,ord = 2,dim = 2),dim=1)[0]\n",
        "    print(\"average GNN feature out_perturb: \")\n",
        "    print(np.mean(out_perturb_feature_GNN.cpu().numpy()))\n",
        "\n",
        "  # evaluate stability performance for 1-layer stable GtNN\n",
        "  model_stable.eval()\n",
        "  with torch.no_grad():\n",
        "    M.evaluate_at_operator_tuple(operator_tuple=operator_tuple_device)\n",
        "    model_stable.change_monomial_word_support(M)\n",
        "    outs_test_stable = model_stable.forward(X_test)\n",
        "    outs_test_stable_hat = model_stable.forward(X_test_hat)\n",
        "    # output perturbation\n",
        "    out_perturb_feature_Stable = torch.max(torch.linalg.vector_norm(outs_test_stable - outs_test_stable_hat,ord = 2,dim = 2),dim=1)[0]\n",
        "    print(\"average stable GNN feature out_perturb: \")\n",
        "    print(np.mean(out_perturb_feature_Stable.cpu().numpy()))\n",
        "\n",
        "  # evaluate stability performance for 2-layer GtNN\n",
        "  model_two_layer_GNN.eval()\n",
        "  with torch.no_grad():\n",
        "    M.evaluate_at_operator_tuple(operator_tuple=operator_tuple_device)\n",
        "    model_two_layer_GNN.change_monomial_word_support(M)\n",
        "    outs_test_two_layer_GNN = model_two_layer_GNN.forward(X_test)\n",
        "    outs_test_two_layer_GNN_hat = model_two_layer_GNN.forward(X_test_hat)\n",
        "    # output perturbation\n",
        "    out_perturb_feature_two_layer_GNN = torch.max(torch.linalg.vector_norm(outs_test_two_layer_GNN - outs_test_two_layer_GNN_hat,ord = 2,dim = 2),dim=1)[0]\n",
        "    print(\"average two layer GNN feature out_perturb: \")\n",
        "    print(np.mean(out_perturb_feature_two_layer_GNN.cpu().numpy()))\n",
        "\n",
        "  # evaluate stability performance for 2-layer stable GtNN\n",
        "  model_two_layer_stable.eval()\n",
        "  with torch.no_grad():\n",
        "    M.evaluate_at_operator_tuple(operator_tuple=operator_tuple_device)\n",
        "    model_two_layer_stable.change_monomial_word_support(M)\n",
        "    outs_test_two_layer_stable = model_two_layer_stable.forward(X_test)\n",
        "    outs_test_two_layer_stable_hat = model_two_layer_stable.forward(X_test_hat)\n",
        "    # output perturbation\n",
        "    out_perturb_feature_two_layer_stable = torch.max(torch.linalg.vector_norm(outs_test_two_layer_stable - outs_test_two_layer_stable_hat,ord = 2,dim = 2),dim=1)[0]\n",
        "    print(\"average two layer stable GNN feature out_perturb: \")\n",
        "    print(np.mean(out_perturb_feature_two_layer_stable.cpu().numpy()))\n",
        "\n",
        "  out_perturb_feature_GNN_all[:,ind_perturb] = out_perturb_feature_GNN.cpu().numpy()\n",
        "  out_perturb_feature_stable_all[:,ind_perturb] = out_perturb_feature_Stable.cpu().numpy()\n",
        "  out_perturb_feature_two_layer_GNN_all[:,ind_perturb] = out_perturb_feature_two_layer_GNN.cpu().numpy()\n",
        "  out_perturb_feature_two_layer_stable_all[:,ind_perturb] = out_perturb_feature_two_layer_stable.cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyPT_s42rnEb"
      },
      "outputs": [],
      "source": [
        "# output perturbation figure\n",
        "fig = plt.figure()\n",
        "plt.rc('font',size=20)\n",
        "plt.scatter(Perturbation_feature_all, np.mean(out_perturb_feature_GNN_all, axis=0), marker='+', label='GtNN', alpha = 0.5)\n",
        "plt.scatter(Perturbation_feature_all, np.mean(out_perturb_feature_stable_all, axis = 0), marker='x', label='stable GtNN', alpha = 0.5)\n",
        "plt.scatter(Perturbation_feature_all, np.mean(out_perturb_feature_two_layer_GNN_all, axis=0), marker='1', label='two layer GtNN', alpha = 0.5)\n",
        "plt.scatter(Perturbation_feature_all, np.mean(out_perturb_feature_two_layer_stable_all, axis=0), marker='.',label='two layer stable GtNN', alpha = 0.5)\n",
        "\n",
        "plt.legend(fontsize = 15)\n",
        "plt.xlabel(\"size of feature perturbation\")\n",
        "plt.ylabel(\"output perturbation\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('peturbation_feature.npy', 'wb') as f:\n",
        "    np.save(f,Perturbation_feature_all)\n",
        "    np.save(f,out_perturb_feature_GNN_all)\n",
        "    np.save(f,out_perturb_feature_stable_all)\n",
        "    np.save(f,out_perturb_feature_two_layer_GNN_all)\n",
        "    np.save(f,out_perturb_feature_two_layer_stable_all)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
